{"cells":[{"cell_type":"markdown","source":["### Predicción de áreas con infraestructura construida a partir de Imágenes Satelitales\n#####Autor: Unidad de Ciencia de Datos (UCD)\n\nEn este cuaderno se aplica el proceso de predicción de áreas con infraestructura construida presentado en el [informe](https://github.com/ucd-dnp/inudaciones_ucd/blob/master/dataSandbox/1_Metodologia/Informe_metodologico.pdf) que puede encontrar en la sección [\"Piloto DataSandbox\"](https://github.com/ucd-dnp/inudaciones_ucd/tree/master/dataSandbox) del presente [repositorio](https://github.com/ucd-dnp/inudaciones_ucd). \n\nPara el adecuado funcionamiento de este ejemplo se deben instalar e importar las siguientes liblerías:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7763092-6563-4e9d-9874-434b754ef6d6"}}},{"cell_type":"code","source":["'''Antes de importar los paquetes instale las siguientes librerías:\n\n    urllib3 version 1.25.8\n    pyproj version 2.4.2.post1\n    GDAL version 3.0.2  \n    Pillow version 7.0.0\n    numpay version 1.18.1\n    matplotlib version 3.1.3\n    OpenCV version 4.1.0\n    tifffile version 2021.1.11\n    Shapely version 1.7.0\n    scikit-image version 0.16.2  \n    scikit-learn version 0.22.1 \n    geopandas version 0.8.1\n    rasterio version 1.1.0\n    pandas version 1.0.1\n    mlflow version 1.11.0\n    descartes version 1.1.0\n\n''' \n\nimport urllib                                    \nimport os                                                                           \nimport math\nimport pyproj                                     \nfrom pyproj import Transformer\nfrom osgeo import gdal                            \nfrom PIL import Image                             \nimport numpy as np                               \nimport matplotlib.pyplot as plt                   \nimport cv2                                       \n\nfrom collections import defaultdict\nfrom contextlib import contextmanager  \nimport tifffile as tiff                           \nfrom tifffile import imread\nfrom shapely.affinity import affine_transform     \nfrom shapely.geometry import MultiPolygon, Polygon \nfrom skimage.exposure import equalize_adapthist, equalize_hist              \nfrom skimage.feature import hog                                                   \n\nfrom skimage.measure import regionprops, label\nfrom skimage.segmentation import quickshift, felzenszwalb,slic\nimport matplotlib.pyplot as plt                                                     \nfrom multiprocessing.dummy import Pool                                              \nimport time\nimport geopandas as gpd                                                           \n\nimport rasterio                                                                   \nfrom rasterio import Affine, MemoryFile\nimport rasterio.mask as mask\nimport pandas as pd                                                                \n\nimport mlflow                                                                      \nimport mlflow.pyfunc\nimport mlflow.sklearn\nfrom mlflow.models.signature import infer_signature\nfrom hyperopt.pyll import scope\nfrom numpy import arange\n\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_auc_score, f1_score, classification_report, confusion_matrix\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n\nimport descartes                                                                    \nimport warnings\n\nfrom hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe559cbe-e475-4b13-a70d-11e6473d701b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Las clases `GoogleMapDownloader` e `imtools` permiten la obtención y procesamiento de imágenes satelitales de google maps correspondientes al área de analisis de interés. Estas se definen en los siguientes comandos."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7cbb495d-f391-41ba-945b-a8571627d03f"}}},{"cell_type":"code","source":["class GoogleMapDownloader:\n    \"\"\"\n    Esta clase genera imágenes de google maps de alta resolución a partir de \n    un conjunto de coordenas (latitud longitud) y nivel de enfoque(zoom). \n    \"\"\"\n \n    def __init__(self, coords= None, zoom=17, tile_size = 256, proj=None,\n                 PIXEL_SIZE_X = 1.1937, PIXEL_SIZE_Y= 1.1860):\n        \"\"\"\n            GoogleMapDownloader Constructor\n            Args:\n                coords:     coordinate Box, (left, top, right, bottom)\n                zoom:       The zoom level of the location required,\n                            ranges from 0 - 23.  defaults to 17\n                tile_size:  Size for tile of google maps\n                proj:       image crs.\n                PIXEL_SIZE_X: pixel size on image (meters) x direction\n                PIXEL_SIZE_Y: pixel size on image (meters) y direction\n        \"\"\"\n        self._coords = coords\n        self._xtile = None\n        self._ytile = None\n        self._zoom = zoom\n        self.map_img = None\n        self.proj = proj\n        self._tile_size = tile_size\n        self._tile_width = None\n        self._tile_height = None\n        self._lat_start = None\n        self._lng_start = None\n        self._psx = PIXEL_SIZE_X\n        self._psy = PIXEL_SIZE_Y\n        self._ntiles = self.computeNtiles()\n        self.generateGTmatrix()\n   \n    \n    def computeNtiles(self):\n        \"\"\"\n            Calcula el número de baldosas necesarias para generar la imágen satelital a partir del conjuto de coordenadas (box).\n           \n            Retorna: número de baldosas\n        \"\"\"\n        x_start, y_start = self.getXY()\n        x_end, y_end = self.getXY(lat=self._coords[2], lon = self._coords[3])\n        xtiles = abs(x_end - x_start) + 1\n        ytiles = abs(y_end - y_start) + 1\n        self._tile_width = xtiles\n        self._tile_height= ytiles\n        return  xtiles*ytiles\n   \n\n    def getLonLat(self, init = True,**kwargs):\n        \"\"\"\n            Genera coordenadas latitud y longitud de la baldosa\n            a partir del sistema de proyección y el nivel de zoom\n            de las coordenadas x e y   \n           \n            Retorna:  La coordenada Lat, Lng de la baldosa\n        \"\"\"\n        zoom = kwargs.get('zoom', self._zoom)\n        xtile = kwargs.get('xtile', self._xtile)\n        ytile = kwargs.get('ytile', self._ytile)\n        n = 2.0 ** zoom\n        lng_start = xtile / n * 360.0 - 180.0\n        lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * ytile / n)))\n        lat_start = math.degrees(lat_rad)\n        if init:\n            self._lat_start, self._lng_start = lat_start, lng_start\n           \n        return (lat_start, lng_start)\n \n    def getXY(self, **kwargs):\n        \"\"\"\n            Genera coordenadas X,Y de la baldosa a partir del sistema de proyección\n            y el nivel de zoom de las coordenadas latitud, longitud\n        \n            Returns: Coodenadas X,Y de la baldosa\n        \"\"\"\n        lon = kwargs.get('lon', self._coords[1])\n        lat = kwargs.get('lat', self._coords[0])\n        lat_rad = math.radians(lat)\n        n = 2.0 ** self._zoom\n        self._xtile = int((lon + 180.0) / 360.0 * n)\n        self._ytile = int((1.0 - math.log(math.tan(lat_rad) + (1 / math.cos(lat_rad))) / math.pi) / 2.0 * n)\n        return (self._xtile, self._ytile)\n   \n    def getXYproj(self, **kwars):\n        \n        lon = self._lng_start\n        lat = self._lat_start\n     \n        transformer = Transformer.from_proj(4326, self.proj)\n     \n        point_y, point_x = transformer.transform(lat, lon, direction='FORWARD')\n       \n        return int(point_x), int(point_y)\n   \n    def getLonLatend(self):\n\n        x_end, y_end = self.getXY(lat=self._coords[2], lon = self._coords[3])\n        lat_end, lng_end = self.getLonLat(xtile=x_end+1, ytile = y_end+1)\n        return (lat_end,lng_end)\n       \n    \n    def generateGTmatrix(self):\n        \"\"\"\n            Genera la matriz Geo Transform para mapear la coordenada de un pixel\n            sobre unas coordenadas georreferenicadas lat, lngt\n           \n            Returns:  geoTransform matrix. Shape (2,3)\n        \"\"\"\n        self.getXY()\n        self.getLonLat()\n        x_min, y_max = self.getXYproj()\n        self.GT = (0.0, self._psx, -self._psy, 0.0,x_min, y_max)\n \n    def generateImage(self, **kwargs):\n        \"\"\"\n            Genera una imagen al unir un conjunto de bladosas de google map\n           \n            Args:\n                start_x:        coordenada de la esquina superior-izquierda baldosa-x \n                start_y:        coordenada de la esquina superior-derecha baldosa-y\n                tile_width:     El número de baldosas a lo ancho de la imagen-\n                                Por defecto es 5\n                tile_height:    El número de baldosas a lo alto de la imagen-\n                                Por defecto es 5\n            Retorna:\n               Una imagen de alta resolución de google maps.\n        \"\"\"\n        tile_size = self._tile_size\n        start_x = kwargs.get('start_x', None)\n        start_y = kwargs.get('start_y', None)\n        tile_width = kwargs.get('tile_width', self._tile_width)\n        tile_height = kwargs.get('tile_height', self._tile_height)\n \n        # Check that we have x and y tile coordinates\n        if start_x == None or start_y == None :\n            start_x, start_y = self.getXY()\n \n        # Determine the size of the image\n        width, height = tile_size * tile_width, tile_size * tile_height\n \n        #Create a new image of the size require\n        self.map_img = Image.new('RGB', (width,height))\n \n        for x in range(0, tile_width):\n            for y in range(0, tile_height) :\n                #url = 'https://mt1.google.com/vt/lyrs=s&?x=' + str(start_x + x) + '&y=' + str(start_y + y) + '&z=' + str( self._zoom)\n                url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/' + str(self._zoom) + '/' + str(start_y + y) + '/' +str(start_x + x)\n                current_tile = str(x)+'-'+str(y)\n                urllib.request.urlretrieve(url,current_tile)\n           \n                im = Image.open(current_tile)\n                self.map_img.paste(im, (x*tile_size, y*tile_size))\n             \n                os.remove(current_tile)\n \n        return self.map_img\n   \n    \n    def save_raster(self, src, filepath):\n       \n        #https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames  -> section Resoluton and scale\n        PIXEL_SIZE_X = self._psx\n        PIXEL_SIZE_Y = self._psy\n        x_pixels = self._tile_width*self._tile_size\n        y_pixels = self._tile_height*self._tile_size\n       \n        self.getLonLat()\n\n        x_min, y_max = self.getXYproj()\n        wkt_projection = pyproj.Proj(self.proj).definition_string()\n     \n        driver = gdal.GetDriverByName('GTiff')\n       \n        dataset = driver.Create(filepath, x_pixels, y_pixels, 3,\n                                gdal.GDT_Float32)\n       \n        dataset.SetGeoTransform((x_min, PIXEL_SIZE_X, 0,\n                                 y_max   , 0, -PIXEL_SIZE_Y))\n       \n        dataset.SetProjection(wkt_projection)\n        dataset.GetRasterBand(1).WriteArray(src[:,:,0])\n        dataset.GetRasterBand(2).WriteArray(src[:,:,1])\n        dataset.GetRasterBand(3).WriteArray(src[:,:,2])\n        dataset.FlushCache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ab3d1f9-8039-45f8-a821-6edf8484b03f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["class imtools():\n\n    def equalize_histogram(image, adaptative = False):\n        temp = image.copy()\n        for ich in range(temp.shape[2]):\n            im = temp[:,:,ich]\n            if not adaptative:\n                im = equalize_hist(im)\n            else:\n                im = equalize_adapthist(im)\n                \n            temp[:,:,ich] = im\n        \n        return temp.astype('float32')\n\n    def Feature_im2hist(image, segments, nbins=16, clrSpc= 'hsv',threads = 8, train=False):\n        start = time.time()\n        print('--- Computing image features ---')\n        if train:\n            n_seg = np.unique(segments)\n        else:\n            n_seg = np.unique(segments)[1:] # el index 0 es background\n            \n        Xfeat = np.zeros((len(n_seg),3*nbins),dtype=np.float32)\n        def poolCalcHist(idx):\n            mask = np.zeros(image.shape[:2],dtype= np.uint8)\n            mask[segments == idx] = 255\n            Npixels = len(mask[segments==idx])\n            if clrSpc == 'hsv':\n                if train:\n                     Xfeat[idx,:nbins] = (cv2.calcHist([image],[0], mask,[nbins],[0,179]).transpose())/Npixels\n                else:\n                     Xfeat[idx-1,:nbins] = (cv2.calcHist([image],[0], mask,[nbins],[0,179]).transpose())/Npixels\n            else:\n                if train:\n                     Xfeat[idx,:nbins] = (cv2.calcHist([image],[0], mask,[nbins],[0,255]).transpose())/Npixels\n                else:\n                     Xfeat[idx-1,:nbins] = (cv2.calcHist([image],[0], mask,[nbins],[0,255]).transpose())/Npixels\n             \n            if train:\n                Xfeat[idx,nbins:2*nbins] = (cv2.calcHist([image],[1], mask,[nbins],[0,255]).transpose())/Npixels\n                Xfeat[idx,2*nbins:3*nbins] = (cv2.calcHist([image],[2], mask,[nbins],[0,255]).transpose())/Npixels\n            else:\n                 Xfeat[idx-1,nbins:2*nbins] = (cv2.calcHist([image],[1], mask,[nbins],[0,255]).transpose())/Npixels\n                 Xfeat[idx-1,2*nbins:3*nbins] = (cv2.calcHist([image],[2], mask,[nbins],[0,255]).transpose())/Npixels\n                 \n        pool = Pool(threads)\n        pool.map(poolCalcHist,n_seg)\n        pool.close()\n        pool.join()\n                \n        print('Done!, Execution time: ',time.time() - start)\n        return Xfeat\n\n    def draw_GT(im= None,labels= None,segments= None,train = False, plot= False):\n        if train:\n            idx = np.unique(segments)[labels==1]\n        else:\n            idx = np.unique(segments)[1:][labels==1]\n        mask = np.isin(segments,idx).astype('uint8')\n        if plot:\n            GT = cv2.bitwise_and(im,im,mask=mask)\n            plt.figure()\n            plt.imshow(GT)\n            plt.axis('off')\n        return mask\n    \n    def get_scalers(image, x_max, y_min):\n        h, w = image.shape[:2]\n        w_ = w * (w / (w + 1))\n        h_ = h * (h / (h + 1))\n        \n        return w_ / x_max, h_ / y_min\n    \n    def mask_for_polygons(shape, polygons):\n        img_mask = np.zeros(shape, np.uint8)\n        if not polygons:\n            return img_mask\n        int_coords = lambda x: np.array(x).round().astype(np.int32)\n        exteriors = [int_coords(poly.exterior.coords) for poly in polygons]\n        interiors = [int_coords(pi.coords) for poly in polygons\n                     for pi in poly.interiors]\n        cv2.fillPoly(img_mask, exteriors, 1)\n        cv2.fillPoly(img_mask, interiors, 0)\n        return img_mask\n        \n    def mask_to_polygons(mask, epsilon=20.0, min_area=7.0):\n        # first, find contours with cv2: it's much faster than shapely\n        contours, hierarchy = cv2.findContours(\n            ((mask == 1) * 255).astype(np.uint8),\n            cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n        # create approximate contours to have reasonable size\n        approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n                           for cnt in contours]\n        if not contours:\n            return MultiPolygon()\n        # now messy stuff to associate parent and child contours\n        cnt_children = defaultdict(list)\n        child_contours = set()\n        assert hierarchy.shape[0] == 1\n        # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n        for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n            if parent_idx != -1:\n                child_contours.add(idx)\n                cnt_children[parent_idx].append(approx_contours[idx])\n        # create actual polygons filtering by area (removes artifacts)\n        all_polygons = []\n        for idx, cnt in enumerate(approx_contours):\n            if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n                assert cnt.shape[1] == 1\n                poly = Polygon(\n                    shell=cnt[:, 0, :],\n                    holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n                           if cv2.contourArea(c) >= min_area])\n                all_polygons.append(poly)\n        # approximating polygons might have created invalid ones, fix them\n        all_polygons = MultiPolygon(all_polygons)\n        if not all_polygons.is_valid:\n            all_polygons = all_polygons.buffer(0)\n            # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n            # need to keep it a Multi throughout\n            if all_polygons.type == 'Polygon':\n                all_polygons = MultiPolygon([all_polygons])\n        return all_polygons\n        \n    def rescale_intensity(image):\n        temp = image.copy()\n        temp = (temp - temp.min())/(temp.max() - temp.min())\n        return temp.astype('float32')\n\n    def scale_percentile(image):\n        vmin = np.percentile(image, 2.0)\n        vmax = np.percentile(image, 98.0)\n        temp = image.copy()\n        temp[temp<vmin] = vmin\n        temp[temp>vmax] = vmax\n        temp = imtools.rescale_intensity(temp)\n        return temp.astype('float32')\n\n    def scale_percentile_by_channel(image):\n        temp = image.copy()\n        for ich in range(temp.shape[2]):\n            im = temp[:,:,ich]\n            vmin = np.percentile(im, 2.0)\n            vmax = np.percentile(im, 98.0)\n            im[im<vmin] = vmin\n            im[im>vmax] = vmax\n            im = (im - im.min()) / (im.max() - im.min())\n            temp[:,:,ich] = im\n            \n        return temp.astype('float32')\n        \n    def show_mask(m):\n        # hack for nice display\n        tiff.imshow(255 * np.stack([m, m, m]));\n    \n    \n    def smooth_image(image, alpha = 5):\n        temp = np.asarray(255*image,dtype = np.uint8)\n        temp = cv2.GaussianBlur(temp,(alpha,alpha),0)\n        temp = imtools.rescale_intensity(temp)\n        return temp.astype('float32')\n      \n    def mapSuperPixels(segments = None, GT =None, proj ={'init':'epsg:4686'} , verbose= True):\n        start = time.time()\n        if verbose: print('---  Mapping superpixels to lat/lng coordinates  ---')\n        seg_properties = regionprops(segments)\n        polygons = [gpd.GeoSeries(Polygon(sp.coords)).convex_hull \n                    for sp in seg_properties if (sp.area>=12)]\n        polygons = [affine_transform(p[0], GT) for p in polygons if p[0].geom_type == 'Polygon']\n        if len(polygons)== 1:\n            if verbose: print('---   Done - execution time: {} seconds'.format(time.time()-start))\n            return gpd.GeoDataFrame({'geometry': polygons}, geometry='geometry', \n                                    crs = proj, index = [0])\n        else:\n            if verbose: print('---   Done - execution time: {} seconds'.format(time.time()-start))\n        return gpd.GeoDataFrame({'geometry': polygons}, geometry='geometry', \n                                    crs = proj)\n            \n    def computeSegments(img, n_seg=20000, compactness = 1.1, method='slic',\n                        convert2lab = True, kernel_size = 5,\n                        scale = 50, mask = None, verbose=True):\n        start = time.time()\n        if verbose: print('---  Computing SuperPixels  ---')\n        if method == 'slic':\n            segments = slic(img, n_segments=n_seg,compactness= compactness,\n                            convert2lab = convert2lab)\n        elif method == 'quickshift':\n            segments = quickshift(img, kernel_size = kernel_size)\n            \n        elif method == 'felzenszwalb':\n            segments = felzenszwalb(img, scale = scale)\n        else:\n            segments = None\n            print(method, 'Not supported')\n        if  mask is not None:   \n            segments[mask] = -1\n            \n        segments = label(segments, connectivity=2, background=-1)\n        \n        if verbose: print('---   Done - execution time: {} seconds'.format(time.time()-start))\n        return segments\n    \n    @contextmanager\n    def convertraster(image, GT):\n        img = image.transpose([2,0,1]).astype('float32')\n        bands, height, width = img.shape\n        transform = Affine(GT[1], 0.0, GT[4],\n                           0.0, GT[2], GT[5])\n        profile = {'driver': 'GTiff', 'dtype': 'float32', 'nodata': None, \n                   'width': width, 'height': height, 'count': bands, 'crs': None, \n                   'transform': transform, \n                   'tiled': False, 'interleave': 'pixel'}\n    \n        with MemoryFile() as memfile:\n            with memfile.open(**profile) as dataset:\n                dataset.write(img)\n                del img\n            with memfile.open() as dataset:\n                yield dataset\n    \n    def maskRasterIm(img, GT, roi_analysis, hogs = False):\n        with imtools.convertraster(img, GT) as raster:\n            out, _ = mask.mask(raster,roi_analysis.geometry, invert = False)\n            m, _, _ = mask.raster_geometry_mask(raster, roi_analysis.geometry, invert=False)\n            if hogs:\n                temp = np.zeros((m.shape[0]//16,m.shape[1]//16), dtype=bool)\n                for i,row in enumerate(range(0,m.shape[0],16)):\n                    for j,col in enumerate(range(0,m.shape[1],16)):\n                        temp[i,j] = m[row,col]\n                m = ~temp.copy()\n            out = out.transpose([1,2,0]).astype('uint8')\n        return out, m\n    \n    def compute_hogs(orientation, image):\n        fd = hog(image, orientations=orientation, pixels_per_cell=(16, 16),\n                 cells_per_block=(1, 1), visualize=False, multichannel=True,\n                 feature_vector=True, transform_sqrt=True)\n        Xfeat = np.reshape(fd,(len(fd)//orientation,orientation))\n        return Xfeat\n    \n    def labelImageHog(img = None, labels= None, pixels = 16):\n        mask = np.zeros(img.shape[:2],dtype=int)\n        yy = labels.reshape((img.shape[0]//pixels,img.shape[1]//pixels))\n        rows, cols = np.where(yy==True)\n      \n        for e, (r, c) in enumerate(zip(rows, cols)):\n            mask[pixels*r:pixels*r+pixels,pixels*c:pixels*c+pixels] = e+1\n      \n        return mask \n    \n    def labelImageHog_piloto(img = None, labels= None, pixels = 16):\n      mask = np.zeros(img.shape[:2],dtype=int)\n      yy = labels.reshape((img.shape[0]//pixels,img.shape[1]//pixels))\n      rows, cols = np.where(yy!=None)\n      \n      for e, (r, c) in enumerate(zip(rows, cols)):\n          mask[pixels*r:pixels*r+pixels,pixels*c:pixels*c+pixels] = e\n      \n      return mask \n    \n    "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85133a9a-bfbc-4721-b449-c0a8a63b7d42"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Haciendo uso de las clases definidas, la siguiente función ejecuta el proceso de predicción de áreas con infraestructura construida.\n\n`image_pred` toma como insumos:\n1. El conjunto de coordenadas de la región a analizar:Este se debe presentar utilizando el formato `(latitud 1, longitud 1, latitud 2, longitud 2)`, donde se hace referencia a la esquina superior izquierda (latitud 1, longitud 1) y a la esquina inferior derecha (latitud 2, longitud 2) del área que se desea análizar. Las coordenadas deben ser especificadas en formato `EPSG:4326 (o WGS84)`, que equivale a la representación cartográfica mundial.\n2. El modelo con el cual se realizará la predicción de las áreas con infraestructura construida: Para utilizar el modelo desarrollado en el presente proyecto consulte el cuaderno \"[Entrenamiento de modelo XGboost](https://github.com/ucd-dnp/inudaciones_ucd/blob/master/dataSandbox/2_Databricks/Entrenamiento.ipynb)\"\n3. La proyección correspondiente a la región de análisis: La proyección empleada por defecto corresponde a la `\"epsg:3115\"` que es la representación cartográfica MagnaSirgas del occidente de Colombia. \n\nPor último, la funciono retorna una tabla de datos georreferenciados (*geodataframe*) que puede ser proyectada, manipulada o descargada utilizando la librería [geopandas](https://geopandas.org). Además, los datos pueden ser utilizadas en programas de análisis GIS como ArcMap y QGIS."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb1dad3d-a656-4123-964c-329e4fc8d84e"}}},{"cell_type":"code","source":["def image_pred(box, model, proj = 'epsg:3115'):\n  \n  '''\n    Función que aplica el proceso de clasificación de cuadrantes dentro de una región de análisis. \n    \n    Argumentos:\n    box -- conjunto de coordenadas (latitud 1, longitud 1, latitud 2, longitud 2) en formato epsg:4326 que representan la región de análisis.\n    model -- Dirección de modelo XGboost con el cual se realiza la estimación de cuadrante con infraestructura construida\n    proj -- formato de proyección deseada para los resultados de la estimación\n    \n    Retorna:\n    rej_pred -- conjunto de datos con cuadrantes clasificados como áreas con infraestructura construida. Los datos contienen la geometría de cada cuadrante en formato 'proj' y la probabilidad estimada de que cada cuadrante sea en realidad un área con construcciones.  \n  '''\n\n  pixels = 8\n  \n  #Procesamiento de imágen Satelital\n  gmd = GoogleMapDownloader(coords=box, proj=proj)\n  img = np.array(gmd.generateImage(), dtype = np.uint8)\n  img = imtools.rescale_intensity(img)\n  img = (imtools.equalize_histogram(img)*255).astype('uint8')\n  img_hsv = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n\n  labels_img = np.arange(img.shape[0]//pixels * img.shape[1]//pixels)  \n  segm_img = imtools.labelImageHog_piloto(img, labels_img, pixels)\n  Xfeat_img = imtools.Feature_im2hist(img_hsv, segm_img, nbins=35, clrSpc='hsv')\n  seg_polygons = imtools.mapSuperPixels(segments=segm_img, GT=gmd.GT, proj = proj,\n                                      verbose=False)\n  Xfeat_img = pd.DataFrame(Xfeat_img).reset_index()\n  x = 1\n  for col in Xfeat_img.columns[1:]:\n    name = 'X' + str(x)\n    Xfeat_img = Xfeat_img.rename(columns={col:name})\n    x = x+1\n  \n  seg_polygons = seg_polygons.reset_index()\n  \n  \n  #Predicción de capa de construcciones\n  X = Xfeat_img\n  \n  with mlflow.start_run():\n    proba = model.predict(X)\n    y_pred = []\n    for i in proba: \n      if i < 0.441:\n        y_pred.append(0) \n      else: \n        y_pred.append(1) \n    \n  X['proba'] = proba\n  X['pred'] = y_pred\n  \n  rej_pred = pd.merge(seg_polygons, X, how='inner', on = 'index', validate = '1:1')\n  rej_pred = rej_pred[[\"index\", \"geometry\", \"proba\", \"pred\"]]\n  rej_pred = rej_pred.loc[rej_pred['pred'] == 1]\n  rej_pred = rej_pred.drop(['pred'], axis=1)\n  rej_pred.columns = ['index', 'geometry', 'probability']\n  rej_pred = rej_pred.drop(['index'], axis = 1)\n  \n  return rej_pred"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee8143f4-1f7a-4eec-897c-83d8f2d44c95"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Aplicación del proceso\n\nUna vez se hayan ejecutado los comandos anteriores, es necesario cargar el modelo previamente entrenado, definir las coordenas de la región de análisis y establecer el formato de proyección a utilizar. El siguiente comando muestra un ejemplo de la aplicación del proceso sobre el municipio de La Plata. En este caso se carga el modelo XGboost desarrollado en el presente proyecto. Para replicar el proceso reemplace la dirección `dbfs:/databricks/mlflow-tracking/2557138525947186/8b6f9e9a241942ecb3cf5c194223ac17/artifacts/model` por la dirección del modelo que entrenó utilizando el cuaderno \"[Entrenamiento de modelo XGboost](https://github.com/ucd-dnp/inudaciones_ucd/blob/master/dataSandbox/2_Databricks/Entrenamiento.ipynb)\" del presente repositorio."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"724a9d6c-cb4f-43e9-8aba-2ba0f627e5ab"}}},{"cell_type":"code","source":["#Cargue el modelo entrenado XGboost \n#---------XGboost--------------\"\"\nlogged_model = 'dbfs:/databricks/mlflow-tracking/2557138525947186/8b6f9e9a241942ecb3cf5c194223ac17/artifacts/model'\nloaded_model_XGboost = mlflow.pyfunc.load_model(logged_model)\n\n#Defina la caja de coordenadas\nbox = (2.397069, -75.896307, 2.3833257, -75.8798396)\n\n#Defina la proyección de coordenadas\nproj = 'epsg:3115'\n\n#Ejecute la función image_pred\nrej_pred_XG = image_pred(box = box , model = loaded_model_XGboost, proj = proj)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0bcba2cd-2206-4359-8a35-b1f5a37ef992"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">--- Computing image features ---\nDone!, Execution time:  105.14043807983398\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">--- Computing image features ---\nDone!, Execution time:  105.14043807983398\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["A continuación se presentan los datos generados por el modelo y la proyección de la capa de construcciones predicha. Esta estimación corresponde al municipio de La Plata en el departamento del Huila, Colombia."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"649bb665-0d97-4a2a-8c29-5685b03e279a"}}},{"cell_type":"code","source":["rej_pred_XG"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7186aeb9-29f0-4583-8387-e36a81efd9b3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[47]: </div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[47]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>geometry</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>159</th>\n      <td>POLYGON ((1132607.936 757182.000, 1132616.292 ...</td>\n      <td>0.868165</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>POLYGON ((1132617.486 757182.000, 1132625.842 ...</td>\n      <td>0.952551</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>POLYGON ((1132627.035 757182.000, 1132635.391 ...</td>\n      <td>0.709258</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>POLYGON ((1132636.585 757182.000, 1132644.941 ...</td>\n      <td>0.601532</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>POLYGON ((1132760.730 757182.000, 1132769.086 ...</td>\n      <td>0.902448</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50085</th>\n      <td>POLYGON ((1132359.646 755066.176, 1132368.002 ...</td>\n      <td>0.911293</td>\n    </tr>\n    <tr>\n      <th>50086</th>\n      <td>POLYGON ((1132369.196 755066.176, 1132377.552 ...</td>\n      <td>0.980929</td>\n    </tr>\n    <tr>\n      <th>50087</th>\n      <td>POLYGON ((1132378.746 755066.176, 1132387.102 ...</td>\n      <td>0.941853</td>\n    </tr>\n    <tr>\n      <th>50089</th>\n      <td>POLYGON ((1132397.845 755066.176, 1132406.201 ...</td>\n      <td>0.565971</td>\n    </tr>\n    <tr>\n      <th>50161</th>\n      <td>POLYGON ((1133085.416 755066.176, 1133093.772 ...</td>\n      <td>0.551958</td>\n    </tr>\n  </tbody>\n</table>\n<p>16642 rows × 2 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>geometry</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>159</th>\n      <td>POLYGON ((1132607.936 757182.000, 1132616.292 ...</td>\n      <td>0.868165</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>POLYGON ((1132617.486 757182.000, 1132625.842 ...</td>\n      <td>0.952551</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>POLYGON ((1132627.035 757182.000, 1132635.391 ...</td>\n      <td>0.709258</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>POLYGON ((1132636.585 757182.000, 1132644.941 ...</td>\n      <td>0.601532</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>POLYGON ((1132760.730 757182.000, 1132769.086 ...</td>\n      <td>0.902448</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50085</th>\n      <td>POLYGON ((1132359.646 755066.176, 1132368.002 ...</td>\n      <td>0.911293</td>\n    </tr>\n    <tr>\n      <th>50086</th>\n      <td>POLYGON ((1132369.196 755066.176, 1132377.552 ...</td>\n      <td>0.980929</td>\n    </tr>\n    <tr>\n      <th>50087</th>\n      <td>POLYGON ((1132378.746 755066.176, 1132387.102 ...</td>\n      <td>0.941853</td>\n    </tr>\n    <tr>\n      <th>50089</th>\n      <td>POLYGON ((1132397.845 755066.176, 1132406.201 ...</td>\n      <td>0.565971</td>\n    </tr>\n    <tr>\n      <th>50161</th>\n      <td>POLYGON ((1133085.416 755066.176, 1133093.772 ...</td>\n      <td>0.551958</td>\n    </tr>\n  </tbody>\n</table>\n<p>16642 rows × 2 columns</p>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["rej_pred_XG.plot()\nplt.axis('off')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ba3c259-34e3-4df5-8485-475c9009e9f4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[48]: </div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[48]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/26bb7d65-ee35-45b0-b0c6-b28789300dc0.png","removedWidgets":[],"addedWidgets":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">(1130973.1041649997, 1133324.812535, 754951.6677, 757288.2063000001)</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(1130973.1041649997, 1133324.812535, 754951.6677, 757288.2063000001)</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"git_Flujo","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3306609469224224}},"nbformat":4,"nbformat_minor":0}
